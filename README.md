# ğŸ§  Content Marketing Agent

An AI-powered platform that automates your **end-to-end content marketing workflow** â€“ from trend collection to polished, export-ready articles using LLMs.

---

## ğŸš€ Features

- ğŸŒ Scrape content from Google, Reddit, YouTube, News, Hacker News, RSS
- ğŸ” Analyze trends, keywords, sentiment, and semantic clusters
- ğŸ§  Generate article topics with LLMs
- ğŸ“ Write structured briefs and long-form articles
- âœ¨ Polish content for tone, SEO, and clarity
- ğŸ“¤ Export to Word (`.docx`), Markdown (`.md`), or email format

---

## ğŸ§­ Master Workflow

1. **Define Themes** â€“ Provide one or more marketing themes (e.g. "AI Agents", "Green Hydrogen")
2. **Select Platforms** â€“ Choose one or more sources like Reddit, Google News, YouTube, etc.
3. **Scrape + Analyze** â€“ Collect real-time data and extract sentiment, keywords, clusters
4. **Generate Topics** â€“ Use LLMs to create clickable article ideas
5. **Write Briefs** â€“ Turn each topic into a structured article brief
6. **Draft Content** â€“ Generate long-form content
7. **Polish** â€“ Refine tone, clarity, and structure
8. **Export** â€“ Save articles in multiple formats

---

## ğŸ“‚ Folder Structure

```bash
content-marketing-agent/
â”‚
â”œâ”€â”€ data/                             # Scraped + analyzed data storage
â”‚   â”œâ”€â”€ content_data.db               # SQLite database for structured content
â”‚   â””â”€â”€ combined_data.csv             # Flattened snapshot of raw content
â”‚
â”œâ”€â”€ guides/                           # Internal documentation
â”‚   â”œâ”€â”€ content-marketing-agent-notes.md
â”‚   â”œâ”€â”€ google-api-setup-guide.md
â”‚   â”œâ”€â”€ TECH_DEBT.md
â”‚   â””â”€â”€ ui-planning-guide.md
â”‚
â”œâ”€â”€ notebooks/                        # Development notebooks
â”‚   â”œâ”€â”€ 01_data_collection.ipynb
â”‚   â”œâ”€â”€ 02_content_analysis.ipynb
â”‚   â”œâ”€â”€ 03_ai_agent_core.ipynb
â”‚   â””â”€â”€ 04_ui_planning.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                       # LLM-powered automation
â”‚   â”‚   â”œâ”€â”€ topic_generator.py
â”‚   â”‚   â”œâ”€â”€ brief_writer.py
â”‚   â”‚   â”œâ”€â”€ content_drafter.py
â”‚   â”‚   â””â”€â”€ content_polisher.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzers/                    # NLP logic and visualizations
â”‚   â”‚   â”œâ”€â”€ trend_sentiment_analyzer.py
â”‚   â”‚   â””â”€â”€ trend_viz.py
â”‚   â”‚
â”‚   â”œâ”€â”€ app/                          # Streamlit UI
â”‚   â”‚   â”œâ”€â”€ ui.py
â”‚   â”‚   â””â”€â”€ tabs/
â”‚   â”‚       â”œâ”€â”€ themes_tab.py
â”‚   â”‚       â”œâ”€â”€ platforms_tab.py
â”‚   â”‚       â”œâ”€â”€ analyze_tab.py
â”‚   â”‚       â”œâ”€â”€ topics_tab.py
â”‚   â”‚       â”œâ”€â”€ briefs_tab.py
â”‚   â”‚       â”œâ”€â”€ draft_tab.py
â”‚   â”‚       â”œâ”€â”€ polish_tab.py
â”‚   â”‚       â””â”€â”€ export_tab.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collection/             # Central scraping logic
â”‚   â”‚   â””â”€â”€ collect_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                    # DB interactions (currently empty)
â”‚   â”‚   â””â”€â”€ db_manager.py (planned)
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                    # Source-specific scrapers
â”‚   â”‚   â”œâ”€â”€ google_search_scraper.py
â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py
â”‚   â”‚   â”œâ”€â”€ hackernews_scraper.py
â”‚   â”‚   â”œâ”€â”€ news_scraper.py
â”‚   â”‚   â”œâ”€â”€ rss_scraper.py
â”‚   â”‚   â””â”€â”€ youtube_scraper.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # Helper functions (currently empty)
â”‚       â”œâ”€â”€ text_cleaning.py (planned)
â”‚       â””â”€â”€ exporter.py (planned)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                             # API keys
â””â”€â”€ README.md
````

---

## ğŸ§ª Local Setup

### 1. Clone

```bash
git clone https://github.com/yourname/content-marketing-agent.git
cd content-marketing-agent
```

### 2. Create Environment

```bash
conda create -n cma python=3.9
conda activate cma
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Configure API Key

Create a `.env` file:

```env
OPENAI_API_KEY=your-api-key-here
```

---

## ğŸ–¥ï¸ UI Tab Flow (Streamlit)

| Step | Tab Name         | Description                            |
| ---- | ---------------- | -------------------------------------- |
| 1    | Define Themes    | Enter broad content themes             |
| 2    | Select Platforms | Choose sources and scrape config       |
| 3    | Analyze Trends   | Extract keywords, sentiments, clusters |
| 4    | Generate Topics  | LLM topic suggestions                  |
| 5    | Write Briefs     | Generate structured briefs per topic   |
| 6    | Draft Content    | Long-form content from each brief      |
| 7    | Polish Content   | Refine tone, grammar, flow             |
| 8    | Export           | Save content as `.docx`, `.md`, email  |

---

## ğŸ“Š Scrapers Summary

| Platform   | Script                     | Notes                         |
| ---------- | -------------------------- | ----------------------------- |
| Google     | `google_search_scraper.py` | SERP-based scraping           |
| Reddit     | `reddit_scraper.py`        | Needs subreddit + keyword     |
| HackerNews | `hackernews_scraper.py`    | Top/Best stories              |
| RSS Feeds  | `rss_scraper.py`           | Simple feedparser integration |
| YouTube    | `youtube_scraper.py`       | Basic metadata + query search |
| NewsAPI    | `news_scraper.py`          | Requires NewsAPI key          |

---

## ğŸ”§ Known Tech Debt

Refer [`guides/TECH_DEBT.md`](./guides/TECH_DEBT.md) for current limitations, UI inconsistencies, and cleanup priorities.

---

## ğŸ§  Tech Stack

* **Python 3.9**
* **Streamlit** â€“ UI framework
* **OpenAI (via LangChain)** â€“ LLM integration
* **SQLite** â€“ Content persistence
* **scikit-learn / NLTK / spaCy** â€“ NLP pipeline
* **Matplotlib / WordCloud / Seaborn** â€“ Visuals
* **fpdf / python-docx** â€“ Export generation

---

## ğŸ“ˆ Example: Run Analysis from Notebook

```python
from src.analyzers.trend_sentiment_analyzer import analyze_trends_and_sentiment

df, embeddings = analyze_trends_and_sentiment()
df.head()
```

---

## ğŸ§‘ Maintainer

**Vinoth Haldorai**
[LinkedIn](https://linkedin.com/in/...) â€¢ [GitHub](https://github.com/...)

---

## ğŸ“œ License

MIT License â€” free for personal + commercial use.

---