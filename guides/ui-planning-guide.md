# ğŸ§­ UI Planning Roadmap for Content Marketing Agent

This document outlines the UI structure, flow, and integration logic for the Streamlit frontend of the **Content Marketing Agent**. The app supports marketing content creation using AI and trend data, structured into 8 logical steps.

---

## ğŸ“ File Location
- **Main UI script:** `src/app/ui.py`
- **Backend Modules:** under `src/`
- **Run with:** `streamlit run src/app/ui.py`

---

## ğŸ§± Overall Layout
- Use **Streamlit sidebar** for step-by-step navigation.
- Use **tabs/pages** or `radio` buttons for linear workflow.
- Use **session state** to track data selections across tabs.

---

## ğŸ§­ 8-Step Workflow & UI Plan

### 1. ğŸ¯ Define Themes
**Purpose**: Capture broad marketing areas of interest.
- UI:
  - Textarea input for comma-separated themes (e.g. "AI Agents, Sustainable Tech")
  - Save to `st.session_state.themes`

---

### 2. ğŸŒ Select Platforms
**Purpose**: Let user choose platforms to scrape.
- UI:
  - Multi-select dropdown: ["Google", "HackerNews", "Reddit", "RSS", "News", "YouTube"]
  - For each platform:
    - If keyword-based: auto-fill from themes
    - If not (e.g. Reddit): ask user to enter subreddit names
- State:
  - Store config in `st.session_state.scraper_config`
  
| Platform    | User Input Required?                  |
| ----------- | ------------------------------------- |
| Google News | No (uses saved themes)                |
| Reddit      | Yes (list of subreddits)              |
| Hacker News | No (uses themes as tags/search terms) |
| YouTube     | Yes (search queries or channels)      |
| RSS Feeds   | Yes (URLs of feeds)                   |
| Web Search  | No (uses themes as keywords)          |


---

### 3. ğŸ“Š Collect & Analyze Trends
**Purpose**: Scrape platforms and analyze for trends and sentiment.
- Triggers `data_collection/collect_data.py`
- Backend uses:
  - Scrapers: `src/scrapers/*.py`
  - Database: SQLite (`data/content_data.db`)
  - Analyzer: `analyzers/trend_sentiment_analyzer.py`
- UI:
  - Button: â€œCollect & Analyzeâ€
  - Display:
    - Sentiment distribution chart
    - Keyword clusters (via UMAP or KMeans)
    - WordCloud of trending terms
    - Table of extracted keywords

---

### 4. ğŸ§  Generate Article Topics
**Purpose**: Use top keywords to generate potential article titles + descriptions.
- Uses `agents/topic_generator.py`
- UI:
  - Multi-select trending keywords
  - Button: â€œGenerate Topicsâ€
  - Display list of suggested topics
  - Allow user to select favorites
- State:
  - Store selected topics in `st.session_state.selected_topics`

---

### 5. âœï¸ Write Briefs
**Purpose**: Generate brief content outlines for selected topics.
- Uses `agents/brief_writer.py`
- UI:
  - Display selected topics
  - Button: â€œGenerate Briefsâ€
  - Show formatted briefs (title + objective + target audience etc.)
  - Allow edit/approval
- State:
  - Store approved briefs in `st.session_state.selected_briefs`

---

### 6. ğŸ“ Draft Content
**Purpose**: Generate full-length draft articles from briefs.
- Uses `agents/content_drafter.py`
- UI:
  - Show brief
  - Button: â€œGenerate Draftâ€
  - Display draft with formatting
- State:
  - Store drafts in `st.session_state.selected_drafts`

---

### 7. ğŸ’„ Polish Content
**Purpose**: Enhance tone, grammar, SEO of drafts.
- Uses `agents/content_polisher.py`
- UI:
  - Select one or more drafts
  - Choose style (formal, casual, SEO, etc.)
  - Button: â€œPolishâ€
  - Show side-by-side comparison
- State:
  - Store polished version in `st.session_state.polished_drafts`

---

### 8. ğŸ“¤ Export Content
**Purpose**: Export polished content to chosen formats.
- UI:
  - Select final content
  - Choose format:
    - .docx
    - .md (markdown)
    - Email copy
  - Button: â€œExportâ€
- Backend:
  - Use `python-docx` or Markdown conversion
  - Trigger file download

---

## ğŸ§° Technical Stack Summary

| Layer          | Tool / Lib              |
|----------------|-------------------------|
| Frontend       | Streamlit               |
| Storage        | SQLite (`content_data.db`) |
| Scrapers       | Custom Python scrapers in `src/scrapers` |
| Analysis       | NLP with `nltk`, `scikit-learn`, `pandas` |
| LLM Agents     | OpenAI via `langchain` agents |
| Visualization  | `matplotlib`, `seaborn`, `wordcloud`, `plotly` |
| Export         | `python-docx`, Markdown, `streamlit.download_button` |

---

## ğŸ” State Management
Use `st.session_state` to store:
- `themes`
- `scraper_config`
- `trend_keywords`
- `selected_topics`
- `selected_briefs`
- `selected_drafts`
- `polished_drafts`

---

## ğŸ—‚ Folder References

```text
src/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ ui.py                     # Streamlit UI
â”‚
â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ trend_sentiment_analyzer.py
â”‚   â””â”€â”€ trend_viz.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ topic_generator.py
â”‚   â”œâ”€â”€ brief_writer.py
â”‚   â”œâ”€â”€ content_drafter.py
â”‚   â””â”€â”€ content_polisher.py
â”‚
â”œâ”€â”€ data_collection/
â”‚   â””â”€â”€ collect_data.py
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ google_search_scraper.py
â”‚   â”œâ”€â”€ hackernews_scraper.py
â”‚   â”œâ”€â”€ news_scraper.py
â”‚   â”œâ”€â”€ reddit_scraper.py
â”‚   â”œâ”€â”€ rss_scraper.py
â”‚   â””â”€â”€ youtube_scraper.py

